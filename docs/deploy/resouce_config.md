# Angel资源配置

---

## **Worker资源预估**
### **Worker个数预估**
为了更好的实现数据并行，Angel可以自由配置Worker的个数。一般情况下，Worker的个数主要取决于总的需要计算的数据量大小。一般的，单个Worker处理的数据量推荐值为1~5GB（未压缩的文本格式数据，其他格式需要乘以对应的压缩比，下同）。

### **Worker内存预估**
Worker的内存使用状况如图所示：
	![][1]
 - **模型（model）**：从PS拉取的当前Worker需要计算的模型部分
 - **模型更新（model delta）**：Worker的Task计算得到的模型更新
 - **合并后的模型更新（merged model delta）**：合并后的模型更新
 - **系统(system buffer)**：Netty框架使用的ByteBuf pool等
 - **格式化后的训练数据(traing data)**：原始的训练数存储在分布式文件系统之上（例如HDFS），在模型训练开始之前，Worker会将分配给自己的训练数据从分布式文件系统上拉取回本地，经过一些格式的转换后存在本地磁盘或者Worker的内存中。为了提高计算性能，建议将格式化后的训练数据存在Worker内存中，原始训练数据大小和格式化后占用内存空间的比率为**1.5：1**，即1.5GB的原始训练数据经格式化并加载到内存中后占用1GB的内存空间（dummy和libsvm格式均为1.5：1左右， dummy略高）。当然，如果内存紧张，可以使用本地磁盘来存储格式化的数据

假设模型部分大小为`S1`，task每轮迭代产生的更新为`S2`，合并后的模型更新为`S3`，训练数据占用的内存为`S4`，系统部分占用内存为`S5`，一个Worker上运行的Task数量为`taskNum`。则一个Worker占用的内存空间为=`taskNum * S1 + 2*taskNum*S2 + S3 + S4 + S5`。一般情况下`S5`可以通过`S1+S3`代替。所以估算方法简化为`(taskNum +1)* S1 + 2*taskNum*S2 + 2*S3 + S4 `。

以LR为例，假设每个Worker 1个Task，模型维度为1亿，每个Worker计算的训练数据为1.5GB。因为LR模型一般为稠密的，计算出的更新也是稠密的，每轮计算需要全部的模型，因此`S1=S2=S3=0.8G`, `S4=1GB`, 所需内存为`2*0.8GB + 2*0.8GB + 2*0.8GB + 1GB = 5.8GB`，再向上取整为6GB。

# **PS资源预估**
## **PS个数预估**
PS个数一般与Worker个数和模型大小相关。PS个数一般会比Worker个数少，但是也不能差距太悬殊，推荐PS个数为Worker个数的1/5~4/5。
## **PS内存预估**
PS的内存使用如图所示：
	![][2]
 - **模型分区（model partitions）**：每个PS会承担模型的一部分
 - **系统（system buffer）**：Netty框架使用的ByteBuf pool等

由于要与多个Worker发生大数据量的交互，需要大量的发送和接收缓冲区。因此，一般情况下系统本身消耗的内存远大于模型分区本身。假设模型分区大小为`S1`, Worker个数为`workerNum`，可以通过下面方式简单估算PS所需内存：`S1 + 2 * workerNum * S1`。

还是以LR为例，假设模型维度为1亿，Worker个数为50，PS个数为10。一个PS承载的模型维度为1000万，因此`S1=0.08GB`, 则估算的PS内存大小为：`0.08G + 2 * 50 * 0.08G=8GB`。

 [1]: ../img/worker_memory.png
 [2]: ../img/ps_memory.png
