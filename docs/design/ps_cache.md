## PS Cache

PS Cache可以在原有的Worker模块上修改，建议改成新的类。目前考虑有如下改动

* **存储策略**
	* 保留原有的参数存储和参数更新存储模块
	* 暂时去掉训练数据存储模块
	* 数据由Torch采用自有方式读取并在GPU中进行训练，可以节省CPU内存
	* 同时减少PS Cache与Torch的耦合，减少工作量
	* 添加更多样化的矩阵存储格式
	* 添加参数缓存策略

* **访问接口**
	* 添加GPU访问接口
	* 完善PS矩阵存取接口
* **调度策略**
	* 更灵活的RPC调度策略，让计算和网络通信保持流水化

* **资源申请策略**
	* 由于PS Cache需要与GPU卡运行在同一台物理机器上，所以在为PS Cache申请资源是必须将计算资源分配在GPU卡所在机器上

* **管理策略**
	* PS Cache心跳维护，状态维护和down 机恢复等
