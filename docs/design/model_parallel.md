## 模型并行

如果模型太大，超过GPU内存限制，可以考虑让每块GPU卡更新模型的一个部分，需要模型的其余部分可以向PS Cache获取。

模型并行的难点在于如何更好的划分模型，减少不同模型划分直接的关联性，目前并无统一方案，可以先在Torch支持手动划分模型的功能。
